{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')  # download if not already done\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>13867</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>Abortion</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>7</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Abortion\\nWomen's Issues (not abortion though)</td>\n",
       "      <td>RT @cappy_yarbrough: Love to see men who will ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:29:43 -0700</td>\n",
       "      <td>629690895479250944</td>\n",
       "      <td>Como</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>13868</td>\n",
       "      <td>Mike Huckabee</td>\n",
       "      <td>0.9611</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7302</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>Mike Huckabee</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @georgehenryw: Who thought Huckabee exceede...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:25:02 -0700</td>\n",
       "      <td>629689719056568320</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>13869</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Positive\\nNeutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Lrihendry: #TedCruz As President, I will a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 07:19:18 -0700</td>\n",
       "      <td>629658075784282112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869</th>\n",
       "      <td>13870</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Women's Issues (not abortion though)</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Women's Issues (not abortion though)</td>\n",
       "      <td>RT @JRehling: #GOPDebate Donald Trump says tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:04 -0700</td>\n",
       "      <td>629697023663546368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870</th>\n",
       "      <td>13871</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>65</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Lrihendry: #TedCruz headed into the Presid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-06 18:22:27 -0700</td>\n",
       "      <td>629462573641920512</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13871 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id               candidate  candidate_confidence relevant_yn  \\\n",
       "0          1  No candidate mentioned                1.0000         yes   \n",
       "1          2            Scott Walker                1.0000         yes   \n",
       "2          3  No candidate mentioned                1.0000         yes   \n",
       "3          4  No candidate mentioned                1.0000         yes   \n",
       "4          5            Donald Trump                1.0000         yes   \n",
       "...      ...                     ...                   ...         ...   \n",
       "13866  13867  No candidate mentioned                1.0000         yes   \n",
       "13867  13868           Mike Huckabee                0.9611         yes   \n",
       "13868  13869                Ted Cruz                1.0000         yes   \n",
       "13869  13870            Donald Trump                1.0000         yes   \n",
       "13870  13871                Ted Cruz                0.9242         yes   \n",
       "\n",
       "       relevant_yn_confidence sentiment  sentiment_confidence  \\\n",
       "0                      1.0000   Neutral                0.6578   \n",
       "1                      1.0000  Positive                0.6333   \n",
       "2                      1.0000   Neutral                0.6629   \n",
       "3                      1.0000  Positive                1.0000   \n",
       "4                      1.0000  Positive                0.7045   \n",
       "...                       ...       ...                   ...   \n",
       "13866                  1.0000  Negative                0.7991   \n",
       "13867                  1.0000  Positive                0.7302   \n",
       "13868                  1.0000  Positive                0.8051   \n",
       "13869                  1.0000  Negative                1.0000   \n",
       "13870                  0.9614  Positive                0.9614   \n",
       "\n",
       "                             subject_matter  subject_matter_confidence  \\\n",
       "0                         None of the above                     1.0000   \n",
       "1                         None of the above                     1.0000   \n",
       "2                         None of the above                     0.6629   \n",
       "3                         None of the above                     0.7039   \n",
       "4                         None of the above                     1.0000   \n",
       "...                                     ...                        ...   \n",
       "13866                              Abortion                     0.6014   \n",
       "13867                     None of the above                     0.9229   \n",
       "13868                     None of the above                     0.9647   \n",
       "13869  Women's Issues (not abortion though)                     0.9202   \n",
       "13870                     None of the above                     0.9242   \n",
       "\n",
       "               candidate_gold  ... relevant_yn_gold retweet_count  \\\n",
       "0                         NaN  ...              NaN             5   \n",
       "1                         NaN  ...              NaN            26   \n",
       "2                         NaN  ...              NaN            27   \n",
       "3                         NaN  ...              NaN           138   \n",
       "4                         NaN  ...              NaN           156   \n",
       "...                       ...  ...              ...           ...   \n",
       "13866  No candidate mentioned  ...              yes             7   \n",
       "13867           Mike Huckabee  ...              yes             1   \n",
       "13868                Ted Cruz  ...              yes            67   \n",
       "13869            Donald Trump  ...              yes           149   \n",
       "13870                Ted Cruz  ...              yes            65   \n",
       "\n",
       "          sentiment_gold                             subject_matter_gold  \\\n",
       "0                    NaN                                             NaN   \n",
       "1                    NaN                                             NaN   \n",
       "2                    NaN                                             NaN   \n",
       "3                    NaN                                             NaN   \n",
       "4                    NaN                                             NaN   \n",
       "...                  ...                                             ...   \n",
       "13866           Negative  Abortion\\nWomen's Issues (not abortion though)   \n",
       "13867                NaN                                             NaN   \n",
       "13868  Positive\\nNeutral                                             NaN   \n",
       "13869                NaN            Women's Issues (not abortion though)   \n",
       "13870           Positive                                             NaN   \n",
       "\n",
       "                                                    text tweet_coord  \\\n",
       "0      RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1      RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2      RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3      RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "...                                                  ...         ...   \n",
       "13866  RT @cappy_yarbrough: Love to see men who will ...         NaN   \n",
       "13867  RT @georgehenryw: Who thought Huckabee exceede...         NaN   \n",
       "13868  RT @Lrihendry: #TedCruz As President, I will a...         NaN   \n",
       "13869  RT @JRehling: #GOPDebate Donald Trump says tha...         NaN   \n",
       "13870  RT @Lrihendry: #TedCruz headed into the Presid...         NaN   \n",
       "\n",
       "                   tweet_created            tweet_id   tweet_location  \\\n",
       "0      2015-08-07 09:54:46 -0700  629697200650592256              NaN   \n",
       "1      2015-08-07 09:54:46 -0700  629697199560069120              NaN   \n",
       "2      2015-08-07 09:54:46 -0700  629697199312482304              NaN   \n",
       "3      2015-08-07 09:54:45 -0700  629697197118861312            Texas   \n",
       "4      2015-08-07 09:54:45 -0700  629697196967903232              NaN   \n",
       "...                          ...                 ...              ...   \n",
       "13866  2015-08-07 09:29:43 -0700  629690895479250944             Como   \n",
       "13867  2015-08-07 09:25:02 -0700  629689719056568320              USA   \n",
       "13868  2015-08-07 07:19:18 -0700  629658075784282112              NaN   \n",
       "13869  2015-08-07 09:54:04 -0700  629697023663546368              NaN   \n",
       "13870  2015-08-06 18:22:27 -0700  629462573641920512  San Antonio, TX   \n",
       "\n",
       "                    user_timezone  \n",
       "0                           Quito  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3      Central Time (US & Canada)  \n",
       "4                         Arizona  \n",
       "...                           ...  \n",
       "13866                         NaN  \n",
       "13867                         NaN  \n",
       "13868                         NaN  \n",
       "13869                         NaN  \n",
       "13870  Central Time (US & Canada)  \n",
       "\n",
       "[13871 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Sentiment.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>RT @cappy_yarbrough: Love to see men who will ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>Mike Huckabee</td>\n",
       "      <td>RT @georgehenryw: Who thought Huckabee exceede...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>RT @Lrihendry: #TedCruz As President, I will a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>RT @JRehling: #GOPDebate Donald Trump says tha...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870</th>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>RT @Lrihendry: #TedCruz headed into the Presid...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13871 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    candidate  \\\n",
       "0      No candidate mentioned   \n",
       "1                Scott Walker   \n",
       "2      No candidate mentioned   \n",
       "3      No candidate mentioned   \n",
       "4                Donald Trump   \n",
       "...                       ...   \n",
       "13866  No candidate mentioned   \n",
       "13867           Mike Huckabee   \n",
       "13868                Ted Cruz   \n",
       "13869            Donald Trump   \n",
       "13870                Ted Cruz   \n",
       "\n",
       "                                                    text sentiment  \n",
       "0      RT @NancyLeeGrahn: How did everyone feel about...   Neutral  \n",
       "1      RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive  \n",
       "2      RT @TJMShow: No mention of Tamir Rice and the ...   Neutral  \n",
       "3      RT @RobGeorge: That Carly Fiorina is trending ...  Positive  \n",
       "4      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive  \n",
       "...                                                  ...       ...  \n",
       "13866  RT @cappy_yarbrough: Love to see men who will ...  Negative  \n",
       "13867  RT @georgehenryw: Who thought Huckabee exceede...  Positive  \n",
       "13868  RT @Lrihendry: #TedCruz As President, I will a...  Positive  \n",
       "13869  RT @JRehling: #GOPDebate Donald Trump says tha...  Negative  \n",
       "13870  RT @Lrihendry: #TedCruz headed into the Presid...  Positive  \n",
       "\n",
       "[13871 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf = df[[\"candidate\",\"text\",\"sentiment\"]]\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "  \"\"\"Removes punctuation from the given text.\"\"\"\n",
    "  return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  \"\"\"Removes stop words from the given text.\"\"\"\n",
    "  stop_words = set(stopwords.words('english'))  # Download stopwords if needed\n",
    "  return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "def preprocess_text(text):\n",
    "  \"\"\"Preprocesses text by removing punctuation, converting to lowercase, and removing stop words.\"\"\"\n",
    "  text = text.lower()  # Convert to lowercase\n",
    "  text = remove_punctuation(text)\n",
    "  text = remove_stopwords(text)\n",
    "  return text\n",
    "\n",
    "def vectorized_preprocess(text_list):\n",
    "    return [preprocess_text(text) for text in text_list]\n",
    "\n",
    "df['text_cleaned'] = np.vectorize(preprocess_text)(df['text'].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>rt nancyleegrahn everyone feel climate change ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>rt scottwalker didnt catch full gopdebate last...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>rt tjmshow mention tamir rice gopdebate held c...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>rt robgeorge carly fiorina trending hours deba...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>rt danscavino gopdebate w realdonaldtrump deli...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>rt cappy_yarbrough love see men never faced pr...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>Mike Huckabee</td>\n",
       "      <td>rt georgehenryw thought huckabee exceeded expe...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>rt lrihendry tedcruz president always tell tru...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>rt jrehling gopdebate donald trump says doesnt...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870</th>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>rt lrihendry tedcruz headed presidential debat...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13871 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    candidate  \\\n",
       "0      No candidate mentioned   \n",
       "1                Scott Walker   \n",
       "2      No candidate mentioned   \n",
       "3      No candidate mentioned   \n",
       "4                Donald Trump   \n",
       "...                       ...   \n",
       "13866  No candidate mentioned   \n",
       "13867           Mike Huckabee   \n",
       "13868                Ted Cruz   \n",
       "13869            Donald Trump   \n",
       "13870                Ted Cruz   \n",
       "\n",
       "                                            text_cleaned sentiment  \n",
       "0      rt nancyleegrahn everyone feel climate change ...   Neutral  \n",
       "1      rt scottwalker didnt catch full gopdebate last...  Positive  \n",
       "2      rt tjmshow mention tamir rice gopdebate held c...   Neutral  \n",
       "3      rt robgeorge carly fiorina trending hours deba...  Positive  \n",
       "4      rt danscavino gopdebate w realdonaldtrump deli...  Positive  \n",
       "...                                                  ...       ...  \n",
       "13866  rt cappy_yarbrough love see men never faced pr...  Negative  \n",
       "13867  rt georgehenryw thought huckabee exceeded expe...  Positive  \n",
       "13868  rt lrihendry tedcruz president always tell tru...  Positive  \n",
       "13869  rt jrehling gopdebate donald trump says doesnt...  Negative  \n",
       "13870  rt lrihendry tedcruz headed presidential debat...  Positive  \n",
       "\n",
       "[13871 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf = df[[\"candidate\",\"text_cleaned\",\"sentiment\"]]\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25     9.0\n",
       "0.50    11.0\n",
       "0.75    13.0\n",
       "0.90    15.0\n",
       "1.00    25.0\n",
       "Name: text_cleaned, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length = newdf['text_cleaned'].apply(lambda x: len(x.split()))\n",
    "text_length.quantile([0.25, 0.50, 0.75, 0.90, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19293"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all text from the text_cleaned column into a single string\n",
    "all_text = ' '.join(newdf['text_cleaned'])\n",
    "\n",
    "# Split the combined text into individual words\n",
    "words = all_text.split()\n",
    "\n",
    "# Convert the list of words into a set to get unique words\n",
    "unique_words = set(words)\n",
    "\n",
    "# Get the total number of unique words\n",
    "num_unique_words = len(unique_words)\n",
    "\n",
    "num_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sequence length (number of words)\n",
    "max_len = 25\n",
    "\n",
    "# 90 percentile sequence length (number of words)\n",
    "len = 15\n",
    "\n",
    "# Number of most frequent words to consider (vocabulary size)\n",
    "vocab_size = num_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tokenizer\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "\n",
    "# Fit Tokenizer on Text Data\n",
    "tokenizer.fit_on_texts(newdf['text_cleaned'].tolist())\n",
    "\n",
    "# Convert Text to Sequences\n",
    "sequences = tokenizer.texts_to_sequences(newdf['text_cleaned'].tolist())\n",
    "\n",
    "# Add padding to Sequences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=len, padding='post')\n",
    "\n",
    "# One hot encoding for target\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(newdf['sentiment'])\n",
    "labels = to_categorical(labels, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Apps\\Anaconda\\envs\\directml\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From e:\\Apps\\Anaconda\\envs\\directml\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From e:\\Apps\\Anaconda\\envs\\directml\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 11096 samples, validate on 2775 samples\n",
      "Epoch 1/40\n",
      "11096/11096 [==============================] - 14s 1ms/sample - loss: 0.8696 - acc: 0.6260 - val_loss: 0.7790 - val_acc: 0.6537\n",
      "Epoch 2/40\n",
      "11096/11096 [==============================] - 13s 1ms/sample - loss: 0.6932 - acc: 0.6975 - val_loss: 0.7581 - val_acc: 0.6739\n",
      "Epoch 3/40\n",
      "11096/11096 [==============================] - 13s 1ms/sample - loss: 0.5792 - acc: 0.7638 - val_loss: 0.7640 - val_acc: 0.6732\n",
      "Epoch 4/40\n",
      "11096/11096 [==============================] - 13s 1ms/sample - loss: 0.4706 - acc: 0.8143 - val_loss: 0.8230 - val_acc: 0.6620\n",
      "Epoch 5/40\n",
      "11096/11096 [==============================] - 13s 1ms/sample - loss: 0.3764 - acc: 0.8624 - val_loss: 0.8974 - val_acc: 0.6717\n",
      "Epoch 6/40\n",
      "11096/11096 [==============================] - 13s 1ms/sample - loss: 0.3159 - acc: 0.8862 - val_loss: 0.9542 - val_acc: 0.6497\n",
      "Epoch 7/40\n",
      "11096/11096 [==============================] - 13s 1ms/sample - loss: 0.2722 - acc: 0.8998 - val_loss: 1.0691 - val_acc: 0.6541\n",
      "Epoch 8/40\n",
      "11096/11096 [==============================] - 14s 1ms/sample - loss: 0.2499 - acc: 0.9078 - val_loss: 1.1306 - val_acc: 0.6494\n",
      "Epoch 9/40\n",
      "11096/11096 [==============================] - 14s 1ms/sample - loss: 0.2243 - acc: 0.9184 - val_loss: 1.2532 - val_acc: 0.6591\n",
      "Epoch 10/40\n",
      "11096/11096 [==============================] - 14s 1ms/sample - loss: 0.2118 - acc: 0.9235 - val_loss: 1.2123 - val_acc: 0.6584\n",
      "Epoch 11/40\n",
      "11096/11096 [==============================] - 14s 1ms/sample - loss: 0.1992 - acc: 0.9269 - val_loss: 1.3546 - val_acc: 0.6472\n",
      "Epoch 12/40\n",
      "11096/11096 [==============================] - 14s 1ms/sample - loss: 0.1896 - acc: 0.9298 - val_loss: 1.3632 - val_acc: 0.6544\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_size, output_dim=len))\n",
    "model.add(SpatialDropout1D(0.2))  # Helps prevent overfitting\n",
    "model.add(LSTM(64, return_sequences=True))  # Process sequences\n",
    "model.add(LSTM(32))  # Extract features\n",
    "model.add(Dense(3, activation='softmax'))  # Output layer for 3 sentiment classes\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss=CategoricalCrossentropy(), optimizer=Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Model training\n",
    "history = model.fit(X_train, y_train, epochs=40, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2775/2775 [==============================] - 1s 223us/sample - loss: 0.7581 - acc: 0.6739\n",
      "Final Validation Accuracy: 0.6739 and Final Validation Loss: 0.7581\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on validation set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Final Validation Accuracy:', round(accuracy,4), 'and Final Validation Loss:', round(loss,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save('Twitter Sentiment Predictor.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
